{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaniamv/dataprocessing/blob/main/spark/examples/06-write_partitioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOA_wQSmLd9z"
      },
      "source": [
        "# Write\n",
        "- .write\n",
        "- .format (parquet, csv, json)\n",
        "- options\n",
        "- spark.sql.sources.partitionOverwriteMode dynamic\n",
        "\n",
        "# Write Mode\n",
        "- overwrite - The overwrite mode is used to overwrite the existing file, alternatively, you can use SaveMode.Overwrite\n",
        "- append - To add the data to the existing file, alternatively, you can use SaveMode.Append\n",
        "- ignore - Ignores write operation when the file already exists, alternatively, you can use SaveMode.Ignore.\n",
        "- errorifexists or error - This is a default option when the file already exists, it returns an error, alternatively, you can use SaveMode.ErrorIfExists.\n",
        "\n",
        "# Partitioning\n",
        "Process to organize the data into multiple chunks based on some criteria.\n",
        "Partitions are organized in sub-folders.\n",
        "Partitioning improves performance in Spark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXeODL0T1fO",
        "outputId": "c410e46c-4a50-43aa-926f-d0417c6280d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "637HFw00T3LP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local').appName('Spark Course').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj3Cg2riVX3m"
      },
      "source": [
        "# Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83BBHcNJDmw4",
        "outputId": "98e422a2-d6fa-4017-c288-61bedd8d58f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-33.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from faker) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Downloading Faker-33.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-33.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z-caHS2MVX3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f1214e-32f2-461a-990e-cb55720e86bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------+--------------------------+----------+-------------------------+----------------+---------------------+\n",
            "|address                                               |date                      |dob       |email                    |name            |phone                |\n",
            "+------------------------------------------------------+--------------------------+----------+-------------------------+----------------+---------------------+\n",
            "|500 Gonzalez Plaza\\nChristopherfort, WA 12756         |2024-05-02 06:13:38.727743|1913-08-19|jonespamela@example.org  |Daniel Lowery   |386-510-9816         |\n",
            "|87024 Katherine Flat\\nSouth Phillipchester, PW 07085  |2024-05-03 04:15:02.234841|1972-10-10|jasonthompson@example.org|Shannon Graham  |001-807-624-1514x3217|\n",
            "|556 Scott Locks\\nDustinmouth, NY 50670                |2024-05-01 16:35:26.89966 |1975-07-05|mwilliams@example.com    |Tammy Rose      |(765)254-9222x0589   |\n",
            "|51662 Brent Loop Apt. 842\\nMichelleport, AZ 38836     |2024-05-03 17:45:10.787435|1954-11-23|samanthaflynn@example.net|Teresa Herring  |+1-713-489-2473x410  |\n",
            "|4852 Aaron Mountain Apt. 698\\nRichardtown, LA 16027   |2024-05-02 05:09:00.696273|1984-12-10|jperez@example.net       |Jennifer Haynes |(694)714-8587        |\n",
            "|624 Sandra Lakes Apt. 467\\nHardingmouth, LA 19068     |2024-05-02 20:35:18.664237|1983-07-18|etaylor@example.net      |Michael Chambers|+1-559-362-4026x363  |\n",
            "|2023 Odonnell Landing Apt. 802\\nRobinsonside, HI 07341|2024-05-04 00:18:58.526252|1931-05-30|timothy16@example.net    |Anthony Knight  |838-460-7419         |\n",
            "|3692 Lewis Ports Suite 584\\nNew Chelseyside, WY 92557 |2024-05-04 01:42:08.070211|2009-05-18|maria08@example.org      |Candace Hatfield|+1-625-948-9746      |\n",
            "|60665 Cameron Place Suite 279\\nJulieshire, SC 56824   |2024-05-04 11:06:24.628717|2005-06-16|courtneyberry@example.com|Leslie Dalton   |(908)989-0371        |\n",
            "|4362 Caitlin Isle Suite 677\\nMichaeltown, KY 19093    |2024-05-04 12:41:22.646474|1941-06-12|qlopez@example.org       |Eric Ramsey     |327-785-1186x28980   |\n",
            "+------------------------------------------------------+--------------------------+----------+-------------------------+----------------+---------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from faker import Faker\n",
        "from datetime import datetime\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "users = []\n",
        "for _ in range(50): #cria 50 linhas\n",
        "    user = {\n",
        "        'date': fake.date_time_between_dates(datetime(2024, 5, 1), datetime(2024, 5, 5)),\n",
        "        'name': fake.name(),\n",
        "        'address': fake.address(),\n",
        "        'email': fake.email(),\n",
        "        'dob': fake.date_of_birth(),\n",
        "        'phone': fake.phone_number()\n",
        "    }\n",
        "    users.append(user)\n",
        "\n",
        "df = spark.createDataFrame(users)\n",
        "\n",
        "df.show(10, False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGXjf6xpBj36"
      },
      "source": [
        "# Writing as PARQUET\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14stpbb4Bj37"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw5IIgebBj37",
        "outputId": "831ca700-2c72-4359-8cc1-9a92f96bb87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000-dce7cf18-8f8a-4de6-a8b3-a15f8d32b2ae-c000.snappy.parquet  _SUCCESS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Writing as PARQUET with no partitions\n",
        "\n",
        "path = \"/content/write_partitioning/parquet_no_partitions\"\n",
        "\n",
        "df.write.mode(\"overwrite\").format(\"parquet\").save(path)\n",
        "\n",
        "!ls /content/write_partitioning/parquet_no_partitions\n",
        "\n",
        "spark.read.format(\"parquet\").load(path).count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing as PARQUET with partitions\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "path = \"/content/write_partitioning/parquet_with_partitions\"\n",
        "\n",
        "# Creating partition column\n",
        "df = df.withColumn(\"date_part\", date_format(col(\"date\"), \"yyyyMMdd\")) #separa em folders com o nome da data e coloca lá os ficheiros particionados\n",
        "\n",
        "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\",\"dynamic\") # enable dynamic partition overwrite - only overwrites partitions that are coming in the dataframe\n",
        "                                                                    # NÃO USAR STATIC NUNCA\n",
        "\n",
        "(df#.where(\"date_part = '20240503'\")\n",
        " .write\n",
        " .mode(\"overwrite\")                                               # overwrites the entire path with the new data\n",
        " .partitionBy(\"date_part\")                                        # partition the data by column - creates sub-folders for each partition\n",
        " .format(\"parquet\")                                               # format of output\n",
        " .save(path))                                                     # path\n",
        "\n",
        "!ls /content/write_partitioning/parquet_with_partitions\n",
        "\n",
        "spark.read.format(\"parquet\").load(path).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWX9WZbPHrL1",
        "outputId": "366ea26c-3f9a-4c16-8aa8-80fe5fc5bdca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'date_part=20240501'  'date_part=20240502'  'date_part=20240503'  'date_part=20240504'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking single partition\n",
        "spark.read.parquet(\"/content/write_partitioning/parquet_with_partitions/date_part=20240502\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B62qu87JsAB",
        "outputId": "06062f3c-0251-4025-f46c-4e44dd6c526c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------+--------------------+-------------------+--------------------+\n",
            "|             address|                date|       dob|               email|               name|               phone|\n",
            "+--------------------+--------------------+----------+--------------------+-------------------+--------------------+\n",
            "|500 Gonzalez Plaz...|2024-05-02 06:13:...|1913-08-19|jonespamela@examp...|      Daniel Lowery|        386-510-9816|\n",
            "|4852 Aaron Mounta...|2024-05-02 05:09:...|1984-12-10|  jperez@example.net|    Jennifer Haynes|       (694)714-8587|\n",
            "|624 Sandra Lakes ...|2024-05-02 20:35:...|1983-07-18| etaylor@example.net|   Michael Chambers| +1-559-362-4026x363|\n",
            "|683 Briggs Tunnel...|2024-05-02 12:41:...|1927-01-21|  ladams@example.net|         Mark Allen|          5778127169|\n",
            "|PSC 0273, Box 378...|2024-05-02 09:20:...|1947-09-07|  mike26@example.org|      Whitney Black|+1-312-435-9026x6...|\n",
            "|496 Cole Landing\\...|2024-05-02 06:01:...|1987-12-04|  ngarza@example.com|      Ashley Gordon|+1-636-944-6659x7...|\n",
            "|16419 Ashley Tunn...|2024-05-02 14:12:...|1919-01-03|leesamantha@examp...|        Sara Watson|    794.236.5390x859|\n",
            "|9115 Christina Pa...|2024-05-02 18:49:...|1931-10-21|gjackson@example.org|      David Garrett|        841-908-1578|\n",
            "|09992 Rita Traffi...|2024-05-02 16:53:...|1972-07-10| amber02@example.net|Christopher Sanders| (329)871-8274x82955|\n",
            "|27256 Eric Spur\\n...|2024-05-02 22:12:...|1964-11-29| atorres@example.org|     Samantha Smith|  227.668.6154x52136|\n",
            "|3414 Smith Lock\\n...|2024-05-02 07:40:...|1915-08-11|   mia69@example.net|      Debra Collier|          4154317366|\n",
            "|5394 Adam Tunnel\\...|2024-05-02 01:05:...|1930-02-08|moonmitchell@exam...|       Albert Booth|   (206)850-1637x425|\n",
            "+--------------------+--------------------+----------+--------------------+-------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing as CSV\n",
        "\n",
        "https://spark.apache.org/docs/3.5.1/sql-data-sources-csv.html"
      ],
      "metadata": {
        "id": "n8mTC5yeNV6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnAWUTeZO43Z",
        "outputId": "86f3a420-e59e-488c-c98b-c86a949e7b71"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/write_partitioning/csv_no_partitioning/\"\n",
        "\n",
        "# write as csv\n",
        "(df\n",
        "  .write\n",
        "  .format(\"csv\")\n",
        "  .mode(\"overwrite\")\n",
        "  .option(\"delimiter\", \"|\")\n",
        "  .option(\"header\", True)\n",
        "  .save(path))\n",
        "\n",
        "# listing files in the folder\n",
        "!ls /content/write_partitioning/csv_no_partitioning/\n",
        "\n",
        "# read as csv\n",
        "(spark\n",
        "  .read\n",
        "  .options(sep=\"|\", multiLine=True, header=True)\n",
        "  .csv(path)\n",
        "  .count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE6zC-HnNYAz",
        "outputId": "73e778f8-659c-4cc4-fa30-e1ed054655af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000-985451ca-b900-48a2-ac64-5c6c8e25e43d-c000.csv  _SUCCESS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing as JSON\n",
        "\n",
        "https://spark.apache.org/docs/3.5.1/sql-data-sources-json.html"
      ],
      "metadata": {
        "id": "ZAuM5-WcTtyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/write_partitioning/json_no_partitioning/\"\n",
        "\n",
        "# write as json\n",
        "(df\n",
        ".write\n",
        ".mode(\"overwrite\")\n",
        ".format(\"json\")\n",
        ".save(path))\n",
        "\n",
        "# listing files in the folder\n",
        "!ls /content/write_partitioning/json_no_partitioning/\n",
        "\n",
        "# read as json\n",
        "(spark\n",
        "  .read\n",
        "  .json(path)\n",
        "  .count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnNgwbtxTsW_",
        "outputId": "34611d36-9eac-45a4-92dd-28ed0325b43e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000-a4834821-8902-4a82-b89d-c3f520350c7b-c000.json  _SUCCESS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading json as text\n",
        "spark.read.text(path).show(10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3hYNCubT0ry",
        "outputId": "b9540f98-bd76-4073-9342-9587adea60c3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                     |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{\"address\":\"500 Gonzalez Plaza\\nChristopherfort, WA 12756\",\"date\":\"2024-05-02T06:13:38.727Z\",\"dob\":\"1913-08-19\",\"email\":\"jonespamela@example.org\",\"name\":\"Daniel Lowery\",\"phone\":\"386-510-9816\",\"date_part\":\"20240502\"}                   |\n",
            "|{\"address\":\"87024 Katherine Flat\\nSouth Phillipchester, PW 07085\",\"date\":\"2024-05-03T04:15:02.234Z\",\"dob\":\"1972-10-10\",\"email\":\"jasonthompson@example.org\",\"name\":\"Shannon Graham\",\"phone\":\"001-807-624-1514x3217\",\"date_part\":\"20240503\"}|\n",
            "|{\"address\":\"556 Scott Locks\\nDustinmouth, NY 50670\",\"date\":\"2024-05-01T16:35:26.899Z\",\"dob\":\"1975-07-05\",\"email\":\"mwilliams@example.com\",\"name\":\"Tammy Rose\",\"phone\":\"(765)254-9222x0589\",\"date_part\":\"20240501\"}                         |\n",
            "|{\"address\":\"51662 Brent Loop Apt. 842\\nMichelleport, AZ 38836\",\"date\":\"2024-05-03T17:45:10.787Z\",\"dob\":\"1954-11-23\",\"email\":\"samanthaflynn@example.net\",\"name\":\"Teresa Herring\",\"phone\":\"+1-713-489-2473x410\",\"date_part\":\"20240503\"}     |\n",
            "|{\"address\":\"4852 Aaron Mountain Apt. 698\\nRichardtown, LA 16027\",\"date\":\"2024-05-02T05:09:00.696Z\",\"dob\":\"1984-12-10\",\"email\":\"jperez@example.net\",\"name\":\"Jennifer Haynes\",\"phone\":\"(694)714-8587\",\"date_part\":\"20240502\"}               |\n",
            "|{\"address\":\"624 Sandra Lakes Apt. 467\\nHardingmouth, LA 19068\",\"date\":\"2024-05-02T20:35:18.664Z\",\"dob\":\"1983-07-18\",\"email\":\"etaylor@example.net\",\"name\":\"Michael Chambers\",\"phone\":\"+1-559-362-4026x363\",\"date_part\":\"20240502\"}         |\n",
            "|{\"address\":\"2023 Odonnell Landing Apt. 802\\nRobinsonside, HI 07341\",\"date\":\"2024-05-04T00:18:58.526Z\",\"dob\":\"1931-05-30\",\"email\":\"timothy16@example.net\",\"name\":\"Anthony Knight\",\"phone\":\"838-460-7419\",\"date_part\":\"20240504\"}           |\n",
            "|{\"address\":\"3692 Lewis Ports Suite 584\\nNew Chelseyside, WY 92557\",\"date\":\"2024-05-04T01:42:08.070Z\",\"dob\":\"2009-05-18\",\"email\":\"maria08@example.org\",\"name\":\"Candace Hatfield\",\"phone\":\"+1-625-948-9746\",\"date_part\":\"20240504\"}         |\n",
            "|{\"address\":\"60665 Cameron Place Suite 279\\nJulieshire, SC 56824\",\"date\":\"2024-05-04T11:06:24.628Z\",\"dob\":\"2005-06-16\",\"email\":\"courtneyberry@example.com\",\"name\":\"Leslie Dalton\",\"phone\":\"(908)989-0371\",\"date_part\":\"20240504\"}          |\n",
            "|{\"address\":\"4362 Caitlin Isle Suite 677\\nMichaeltown, KY 19093\",\"date\":\"2024-05-04T12:41:22.646Z\",\"dob\":\"1941-06-12\",\"email\":\"qlopez@example.org\",\"name\":\"Eric Ramsey\",\"phone\":\"327-785-1186x28980\",\"date_part\":\"20240504\"}               |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading json as text\n",
        "spark.read.json(path).show(10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bHcT2ilUo_F",
        "outputId": "d176b2b4-2f6f-422c-e8a1-2e18f130cf7d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------+------------------------+---------+----------+-------------------------+----------------+---------------------+\n",
            "|address                                               |date                    |date_part|dob       |email                    |name            |phone                |\n",
            "+------------------------------------------------------+------------------------+---------+----------+-------------------------+----------------+---------------------+\n",
            "|500 Gonzalez Plaza\\nChristopherfort, WA 12756         |2024-05-02T06:13:38.727Z|20240502 |1913-08-19|jonespamela@example.org  |Daniel Lowery   |386-510-9816         |\n",
            "|87024 Katherine Flat\\nSouth Phillipchester, PW 07085  |2024-05-03T04:15:02.234Z|20240503 |1972-10-10|jasonthompson@example.org|Shannon Graham  |001-807-624-1514x3217|\n",
            "|556 Scott Locks\\nDustinmouth, NY 50670                |2024-05-01T16:35:26.899Z|20240501 |1975-07-05|mwilliams@example.com    |Tammy Rose      |(765)254-9222x0589   |\n",
            "|51662 Brent Loop Apt. 842\\nMichelleport, AZ 38836     |2024-05-03T17:45:10.787Z|20240503 |1954-11-23|samanthaflynn@example.net|Teresa Herring  |+1-713-489-2473x410  |\n",
            "|4852 Aaron Mountain Apt. 698\\nRichardtown, LA 16027   |2024-05-02T05:09:00.696Z|20240502 |1984-12-10|jperez@example.net       |Jennifer Haynes |(694)714-8587        |\n",
            "|624 Sandra Lakes Apt. 467\\nHardingmouth, LA 19068     |2024-05-02T20:35:18.664Z|20240502 |1983-07-18|etaylor@example.net      |Michael Chambers|+1-559-362-4026x363  |\n",
            "|2023 Odonnell Landing Apt. 802\\nRobinsonside, HI 07341|2024-05-04T00:18:58.526Z|20240504 |1931-05-30|timothy16@example.net    |Anthony Knight  |838-460-7419         |\n",
            "|3692 Lewis Ports Suite 584\\nNew Chelseyside, WY 92557 |2024-05-04T01:42:08.070Z|20240504 |2009-05-18|maria08@example.org      |Candace Hatfield|+1-625-948-9746      |\n",
            "|60665 Cameron Place Suite 279\\nJulieshire, SC 56824   |2024-05-04T11:06:24.628Z|20240504 |2005-06-16|courtneyberry@example.com|Leslie Dalton   |(908)989-0371        |\n",
            "|4362 Caitlin Isle Suite 677\\nMichaeltown, KY 19093    |2024-05-04T12:41:22.646Z|20240504 |1941-06-12|qlopez@example.org       |Eric Ramsey     |327-785-1186x28980   |\n",
            "+------------------------------------------------------+------------------------+---------+----------+-------------------------+----------------+---------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# partition json data + saveAsTable\n",
        "\n",
        "# Creating partition column\n",
        "df = df.withColumn(\"date_part\", date_format(col(\"date\"), \"yyyyMMdd\"))\n",
        "\n",
        "# write as json\n",
        "(df.write\n",
        "  .partitionBy(\"date_part\")\n",
        "  .mode(\"overwrite\")\n",
        "  .format(\"json\")\n",
        "  .saveAsTable(\"tbl_json_part\"))\n",
        "\n",
        "# read as json\n",
        "print(spark.table(\"tbl_json_part\").count())\n",
        "\n",
        "# read as json\n",
        "spark.sql(\"show partitions tbl_json_part\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj59UNMuU0hV",
        "outputId": "f047722b-0266-4ef1-b1e4-6bdfd0b6b369"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "+------------------+\n",
            "|         partition|\n",
            "+------------------+\n",
            "|date_part=20240501|\n",
            "|date_part=20240502|\n",
            "|date_part=20240503|\n",
            "|date_part=20240504|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"show tables from default\").show()"
      ],
      "metadata": {
        "id": "RLrqUfZy2uWb",
        "outputId": "39c15d1b-ebf2-4134-8b8b-14dacc7244fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+-----------+\n",
            "|namespace|    tableName|isTemporary|\n",
            "+---------+-------------+-----------+\n",
            "|  default|tbl_json_part|      false|\n",
            "+---------+-------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Append Mode"
      ],
      "metadata": {
        "id": "6RhijzyqZeeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing as PARQUET with APPEND - ATENÇAO AOS DUPLICADOS pq o append tá sempre a adicionar linhas\n",
        "\n",
        "path = \"/content/write_partitioning/parquet_append\"\n",
        "\n",
        "df.write.mode(\"append\").format(\"parquet\").save(path)\n",
        "\n",
        "!ls /content/write_partitioning/parquet_append\n",
        "\n",
        "spark.read.format(\"parquet\").load(path).count()"
      ],
      "metadata": {
        "id": "GmLjA1zDZeG_",
        "outputId": "87d74088-d0e7-4298-ddf4-eacc841791a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000-02fc0145-ba69-450c-9e6b-7e754bb4e45e-c000.snappy.parquet  _SUCCESS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/parquet_folder/20240602\n",
        "\n",
        "#Forma Spark de particionar : Hive-style\n",
        "/parquet_folder/date_part=20240602"
      ],
      "metadata": {
        "id": "VHfw7Bn15Wyu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}